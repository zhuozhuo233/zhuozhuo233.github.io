<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 6.2.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"zhuozhuo233.github.io","root":"/","scheme":"Gemini","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta name="description" content="1.Hadoop概述">
<meta property="og:type" content="article">
<meta property="og:title" content="Hadoop笔记">
<meta property="og:url" content="https://zhuozhuo233.github.io/2023/03/08/Hadoop%E7%AC%94%E8%AE%B0/index.html">
<meta property="og:site_name" content="倬倬吃三碗">
<meta property="og:description" content="1.Hadoop概述">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://zhuozhuo233.github.io/2023/03/08/Hadoop%E7%AC%94%E8%AE%B0/clip_image002.png">
<meta property="og:image" content="https://zhuozhuo233.github.io/2023/03/08/Hadoop%E7%AC%94%E8%AE%B0/clip_image002-1678239885905.png">
<meta property="og:image" content="https://zhuozhuo233.github.io/2023/03/08/Hadoop%E7%AC%94%E8%AE%B0/clip_image001.png">
<meta property="og:image" content="https://zhuozhuo233.github.io/2023/03/08/Hadoop%E7%AC%94%E8%AE%B0/clip_image002-1678244903740.png">
<meta property="og:image" content="https://zhuozhuo233.github.io/2023/03/08/Hadoop%E7%AC%94%E8%AE%B0/clip_image002-1678326750410.png">
<meta property="og:image" content="https://zhuozhuo233.github.io/2023/03/08/Hadoop%E7%AC%94%E8%AE%B0/clip_image002-1678328490579.png">
<meta property="article:published_time" content="2023-03-08T01:31:09.964Z">
<meta property="article:modified_time" content="2023-03-17T05:35:07.646Z">
<meta property="article:author" content="倬倬吃三碗">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://zhuozhuo233.github.io/2023/03/08/Hadoop%E7%AC%94%E8%AE%B0/clip_image002.png">

<link rel="canonical" href="https://zhuozhuo233.github.io/2023/03/08/Hadoop%E7%AC%94%E8%AE%B0/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>

  <title>Hadoop笔记 | 倬倬吃三碗</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">倬倬吃三碗</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-fw fa-home"></i>首页</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-fw fa-th"></i>分类</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-fw fa-archive"></i>归档</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://zhuozhuo233.github.io/2023/03/08/Hadoop%E7%AC%94%E8%AE%B0/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/zaomiao2.jpg">
      <meta itemprop="name" content="倬倬吃三碗">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="倬倬吃三碗">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Hadoop笔记
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2023-03-08 09:31:09" itemprop="dateCreated datePublished" datetime="2023-03-08T09:31:09+08:00">2023-03-08</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2023-03-17 13:35:07" itemprop="dateModified" datetime="2023-03-17T13:35:07+08:00">2023-03-17</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF/" itemprop="url" rel="index"><span itemprop="name">大数据技术</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h1 id="1-Hadoop概述"><a href="#1-Hadoop概述" class="headerlink" title="1.Hadoop概述"></a>1.Hadoop概述</h1><span id="more"></span>

<p><strong>Hadoop优势</strong></p>
<ul>
<li><strong>高可靠性</strong>：Hadoop底层维护多个数据副本，即使某个计算元素活存储出现故障也不会导致数据丢失</li>
<li><strong>高扩展性</strong>：集群分布，方便扩展节点</li>
<li><strong>高效性</strong>：MapReduce下，集群分配子任务并行工作，加快处理速度</li>
<li><strong>高容错性</strong>：失败的任务将会自动重新分配</li>
</ul>
<p><strong>HDFS</strong></p>
<ul>
<li><strong>NameNode(nn)<strong>：存储文件的</strong>元数据</strong>，如<strong>文件名</strong>，<strong>文件目录结构</strong>，<strong>文件属性</strong>(生成时间，副本数，文件权限)，以及每个文件的<strong>块列表</strong>和<strong>块所在</strong>的DataNode</li>
<li><strong>DataNode(dn)<strong>：于本地文件系统存储</strong>文件块数据</strong>，<strong>块数据的校验和</strong></li>
<li>Secondary NameNode(2nn)：每隔一段时间对NameNode元数据<strong>备份</strong></li>
</ul>
<p><img src="/2023/03/08/Hadoop%E7%AC%94%E8%AE%B0/clip_image002.png" alt="img"></p>
<p><strong>MapReduce</strong></p>
<ul>
<li>Map阶段并行处理输入数据</li>
<li>Reduce阶段对Map结果进行汇总</li>
<li>Split -&gt; Map -&gt; Shuffle -&gt; Reduce</li>
</ul>
<p><img src="/2023/03/08/Hadoop%E7%AC%94%E8%AE%B0/clip_image002-1678239885905.png" alt="img"></p>
<p><strong>YARN</strong></p>
<ul>
<li><p>**ResourceManager(RM)**：整体集群资源(内存，CPU…)管理者</p>
</li>
<li><p>**NodeManager(NM)**：单个节点服务器资源管理者</p>
</li>
<li><p>**ApplicationMaster(AM)**：单个任务运行管理者</p>
</li>
<li><p><strong>Container</strong>：容器，封装任务运行所需要的资源(内存，CPU，磁盘，网络…)</p>
</li>
</ul>
<p><img src="/2023/03/08/Hadoop%E7%AC%94%E8%AE%B0/clip_image001.png" alt="img"></p>
<p>客户端可以有多个</p>
<p>集群上可以运行多个ApplicationMaster</p>
<p>每个NodeManager上可以有多个Container</p>
<p><strong>相关生态圈</strong></p>
<ul>
<li><p><strong>Sqoop</strong>：Hadoop，Hive，MySQL等之间进行数据传输，可以将HDFS与关系型数据库互传</p>
</li>
<li><p><strong>ZooKeeper</strong>：针对分布式系统的协调系统，配置维护，名字服务，分布式同步，组服务</p>
</li>
<li><p><strong>Kafaka</strong>：消息队列，高吞吐量的分布式发布订阅消息系统</p>
</li>
<li><p><strong>Fflume</strong>：高可用，高可靠的分布式海量日志采集，聚合与传输系统</p>
</li>
<li><p><strong>Spark</strong>：基于内存的大数据计算框架</p>
</li>
<li><p><strong>Flink</strong>：基于内存的大数据计算框架，多用于处理实时流</p>
</li>
<li><p><strong>Azkaban</strong>：工作流程调度管理系统</p>
</li>
<li><p><strong>Oozie</strong>：工作流程调度管理系统</p>
</li>
<li><p><strong>Hive</strong>：数据仓库工具，将结构化的数据文件映射为一张数据库表，提供简单的SQL查询功能，可将SQL语句转换为MapReduce任务运行</p>
</li>
<li><p><strong>Hbase</strong>：分布式，面向列的非结构化数据库</p>
</li>
</ul>
<h1 id="2-HDFS"><a href="#2-HDFS" class="headerlink" title="2.HDFS"></a>2.HDFS</h1><h2 id="2-1-HDFS定义"><a href="#2-1-HDFS定义" class="headerlink" title="2.1 HDFS定义"></a>2.1 HDFS定义</h2><p><strong>1.背景定义</strong></p>
<p><strong>HDFS(Hadoop Distributed File System)<strong>是一个通过</strong>目录树</strong>来定位文件的分布式文件系统，适合<strong>一次写入</strong>，<strong>多次读出</strong>的场景。</p>
<p><strong>2.HDFS优点</strong></p>
<ul>
<li><p><strong>高容错性</strong>：</p>
<ul>
<li><p>数据自动保存<strong>多个副本</strong>，还可以增加副本提供容错</p>
</li>
<li><p>某个副本丢失后可以<strong>自动恢复</strong></p>
</li>
</ul>
</li>
<li><p><strong>适合处理大数据</strong>：</p>
<ul>
<li>数据规模可以打到GB，TB，PB级别</li>
<li>能够处理百万级别的文件数量</li>
</ul>
</li>
<li><p><strong>造价低廉，通过副本机制提高可靠性</strong></p>
</li>
</ul>
<p><strong>3.HDFS缺点</strong>：</p>
<ul>
<li><p><strong>不适合低延时数据访问</strong>：</p>
<ul>
<li>不适合毫秒级的存储数据，不适合实时存储</li>
</ul>
</li>
<li><p><strong>小文件问题</strong>：</p>
<ul>
<li>存储大量<strong>小文件</strong>会占用<strong>NameNode</strong>的大量<strong>内存</strong>来存储<strong>文件目录</strong>和<strong>块信息</strong></li>
<li>小文件存储的<strong>寻址时间</strong>会超过<strong>读取时间</strong>，违反HDFS设计初衷</li>
</ul>
</li>
<li><p><strong>不支持并发写入</strong>：</p>
<ul>
<li>不允许多线程同时写</li>
<li>仅支持数据追加(append)，不支持文件其他修改</li>
</ul>
</li>
</ul>
<h2 id="2-2-HDFS组成架构"><a href="#2-2-HDFS组成架构" class="headerlink" title="2.2 HDFS组成架构"></a>2.2 HDFS组成架构</h2><p><img src="/2023/03/08/Hadoop%E7%AC%94%E8%AE%B0/clip_image002-1678244903740.png" alt="img"></p>
<ul>
<li><strong>NameNode(nm)</strong><ul>
<li>管理HDFS的名称空间</li>
<li>配置副本策略</li>
<li>管理数据块(Block)映射信息</li>
<li>处理客户端读写请求</li>
</ul>
</li>
<li><strong>DataNode(DN)</strong><ul>
<li>存储实际的数据块(Bolck)</li>
<li>执行数据块的读写操作</li>
</ul>
</li>
<li><strong>Client</strong>：<ul>
<li>文件切分；文件由本地上传HDFS时先由Client将文件切分为一个一个Block，再上传</li>
<li>与NameNode交互，获取文件的位置信息</li>
<li>与DataNode交互，读取&#x2F;写入数据</li>
<li>Client提供一些HDFS管理命令，如NameNode格式化等</li>
<li>Client通过一些命令访问HDFS，可对HDFS进行增删查改</li>
</ul>
</li>
<li><strong>Secondary NameNode</strong>:<ul>
<li>辅助NameNode，分担其工作量，如定期合并<strong>Fsimage</strong>(HDFS元数据的一个<strong>永久性检查点</strong>，包含<strong>HDFS目录</strong>和文件的id，类型，目录，用户等<strong>序列化信息</strong>)和<strong>Edits</strong>(存放HDFS的所有更新操作的路径，记录client执行的写操作)，并推送给NameNode</li>
<li>紧急情况下，辅助恢复NameNode</li>
</ul>
</li>
</ul>
<h2 id="2-3-HDFS文件块大小"><a href="#2-3-HDFS文件块大小" class="headerlink" title="2.3 HDFS文件块大小"></a>2.3 HDFS文件块大小</h2><p>HDFS中的文件在物理上是分块存储(Block)，块大小可以配置参数(<strong>dfs.blocksize</strong>)来规定，默认大小为<strong>128M</strong>,1.X版本为<strong>64M</strong></p>
<p>一种观点认为：寻址时间为传输时间的1%时为最佳</p>
<ul>
<li>HDFS块设置太小，会增加寻址时间，耗费时间在寻找块的开始位置上</li>
<li>HDFS块设置太大，从磁盘传输数据的时间明显大于定位块开始位置所需的时间，导致程序处理数据慢</li>
</ul>
<p>eg.</p>
<p>如果寻址时间为10ms，理想传输时间&#x3D;10ms&#x2F;0.01&#x3D;1000ms&#x3D;1s</p>
<p>磁盘传输速率普遍为100MB&#x2F;s</p>
<p>5个block大小&#x3D;1s*100MB&#x2F;s&#x3D;100MB</p>
<h2 id="2-4-HDFS基本命令"><a href="#2-4-HDFS基本命令" class="headerlink" title="2.4 HDFS基本命令"></a>2.4 HDFS基本命令</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs 命令</span><br><span class="line">hdfs dfs 命令</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">[-appendToFile &lt;localsrc&gt; ... &lt;dst&gt;]</span><br><span class="line">[-cat [-ignoreCrc] &lt;src&gt; ...]</span><br><span class="line">[-chgrp [-R] GROUP PATH...]</span><br><span class="line">[-chmod [-R] &lt;MODE[,MODE]... | OCTALMODE&gt; PATH...]</span><br><span class="line">[-chown [-R] [OWNER][:[GROUP]] PATH...]</span><br><span class="line">[-copyFromLocal [-f] [-p] &lt;localsrc&gt; ... &lt;dst&gt;]</span><br><span class="line">[-copyToLocal [-p] [-ignoreCrc] [-crc] &lt;src&gt; ...&lt;localdst&gt;]</span><br><span class="line">[-count [-q] &lt;path&gt; ...]</span><br><span class="line">[-cp [-f] [-p] &lt;src&gt; ... &lt;dst&gt;]</span><br><span class="line">[-df [-h] [&lt;path&gt; ...]]</span><br><span class="line">[-du [-s] [-h] &lt;path&gt; ...]</span><br><span class="line">[-get [-p] [-ignoreCrc] [-crc] &lt;src&gt; ... &lt;localdst&gt;]</span><br><span class="line">[-getmerge [-nl] &lt;src&gt; &lt;localdst&gt;]</span><br><span class="line">[-help [cmd ...]]</span><br><span class="line">[-ls [-d] [-h] [-R] [&lt;path&gt; ...]]</span><br><span class="line">[-mkdir [-p] &lt;path&gt; ...]</span><br><span class="line">[-moveFromLocal &lt;localsrc&gt; ... &lt;dst&gt;]</span><br><span class="line">[-moveToLocal &lt;src&gt; &lt;localdst&gt;]</span><br><span class="line">[-mv &lt;src&gt; ... &lt;dst&gt;]</span><br><span class="line">[-put [-f] [-p] &lt;localsrc&gt; ... &lt;dst&gt;]</span><br><span class="line">[-rm [-f] [-r|-R] [-skipTrash] &lt;src&gt; ...]</span><br><span class="line">[-rmdir [--ignore-fail-on-non-empty] &lt;dir&gt; ...]&lt;acl_spec&gt; &lt;path&gt;]]</span><br><span class="line">[-setrep [-R] [-w] &lt;rep&gt; &lt;path&gt; ...]</span><br><span class="line">[-stat [format] &lt;path&gt; ...]</span><br><span class="line">[-tail [-f] &lt;file&gt;]</span><br><span class="line">[-test -[defsz] &lt;path&gt;]</span><br><span class="line">[-text [-ignoreCrc] &lt;src&gt; ...]</span><br></pre></td></tr></table></figure>

<p><strong>参数提醒</strong></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -help 命令</span><br></pre></td></tr></table></figure>

<p><strong>上传</strong></p>
<ul>
<li><strong>moveFromLocal</strong></li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">本地剪切到HDFS</span></span><br><span class="line">hadoop fs -moveFromLocal /本地文件路径 /HDFS路径</span><br></pre></td></tr></table></figure>

<ul>
<li><strong>copyFromLocal</strong></li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">本地复制到HDFS</span></span><br><span class="line">hadoop fs -copyFromLocal /本地文件路径 /HDFS路径</span><br></pre></td></tr></table></figure>

<ul>
<li><strong>put</strong></li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">等同于copyFrom Local</span></span><br></pre></td></tr></table></figure>

<ul>
<li><strong>appendToFile</strong></li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">追加一个文件到已存在得文件末尾</span></span><br><span class="line">hadoop fs -appendToFile /本地文件路径 /HDFS文件路径</span><br></pre></td></tr></table></figure>

<p><strong>下载</strong></p>
<ul>
<li><strong>copyToLocal</strong></li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -copyToLocal /HDFS文件路径 /本地文件路径</span><br></pre></td></tr></table></figure>

<ul>
<li><strong>get</strong></li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">等同于copyToLocal</span></span><br></pre></td></tr></table></figure>

<p><strong>HDFS操作</strong></p>
<ul>
<li><strong>ls</strong>显示目录信息</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -ls /HDFS路径</span><br></pre></td></tr></table></figure>

<ul>
<li><strong>cat</strong>显示文件内容</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -cat /HDFS文件路径</span><br></pre></td></tr></table></figure>

<ul>
<li><strong>chgrp&#x2F;chmod&#x2F;chown</strong></li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -chmod 666</span><br><span class="line">hadoop fs -chown 原用户:新用户 /HDFS文件路径</span><br></pre></td></tr></table></figure>

<ul>
<li><strong>mkdir</strong>创建路径</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -mkdir /HDFS路径</span><br></pre></td></tr></table></figure>

<ul>
<li><strong>cp</strong>拷贝</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -cp /原HDFS文件路径 /目标HDFS文件路径</span><br></pre></td></tr></table></figure>

<ul>
<li><strong>mv</strong>移动</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -mv /原HDFS文件路径 /新HDFS文件路径</span><br></pre></td></tr></table></figure>

<ul>
<li><strong>tail</strong>显示文件末尾1kb的数据</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -tail /HDFS文件路径</span><br></pre></td></tr></table></figure>

<ul>
<li><strong>rm</strong>删除文件&#x2F;目录</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -rm /HDFS路径</span><br></pre></td></tr></table></figure>

<ul>
<li><strong>rm -r</strong>递归删除目录及目录里的内容</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -rm -r /HDFS目标目录</span><br></pre></td></tr></table></figure>

<ul>
<li><strong>du</strong>统计文件夹的大小信息</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -du -s -h /HDFS文件夹目录</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">返回</span></span><br><span class="line">27 81 /目录</span><br><span class="line">文件大小 *3个副本大小 目录</span><br></pre></td></tr></table></figure>

<ul>
<li><strong>setrep</strong>设置HDFS副本数量</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -setrep 10 /HDFS文件路径</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">该设置只是记录再NameNode元数据中，真实情况依赖于DataNode数量，如果只有3台设备则最多3个副本，只有当真的有10台节点的时候，副本数才能打到10</span></span><br></pre></td></tr></table></figure>

<h2 id="2-5-HDFS-API"><a href="#2-5-HDFS-API" class="headerlink" title="2.5 HDFS API"></a>2.5 HDFS API</h2><p>暂时先不写</p>
<h2 id="2-6-HDFS读写流程"><a href="#2-6-HDFS读写流程" class="headerlink" title="2.6 HDFS读写流程"></a>2.6 HDFS读写流程</h2><h3 id="2-6-1-HDFS写入流程"><a href="#2-6-1-HDFS写入流程" class="headerlink" title="2.6.1 HDFS写入流程"></a>2.6.1 HDFS写入流程</h3><p>通过client客户端中的DistributedFileSystem模块与NameNode进行交互，FSDataOutputStream模块与DataNode进行交互</p>
<p><img src="/2023/03/08/Hadoop%E7%AC%94%E8%AE%B0/clip_image002-1678326750410.png" alt="img"></p>
<ul>
<li><p>client通过Distributed FileSystem模块向NameNode请求上传文件，NameNode检查目标文件路径是否存在</p>
</li>
<li><p>NameNode返回是否可以上传</p>
</li>
<li><p>client请求第一个block上传到哪几个DataNode服务器上</p>
</li>
<li><p>NameNode返回3个DataNode节点，dn1,dn2,dn3</p>
</li>
<li><p>client通过FSDataOutputStream模块请求dn1上传数据，dn1收到请求后调用dn2，dn2又调用dn3，建立完整通信管道</p>
</li>
<li><p>dn1,dn2,dn3逐级响应客户端</p>
</li>
<li><p>client往dn1上传第一个block，以Packet为单位，dn1收到一个Packet就会传给dn2，dn2传给dn3，每传一个packet会放入一个应答队列等待应答</p>
</li>
<li><p>当一个block传输完成后，客户端再次请求NameNode上传第二个block(重复之前的的操作)</p>
</li>
</ul>
<h3 id="2-6-2-HDFS读取流程"><a href="#2-6-2-HDFS读取流程" class="headerlink" title="2.6.2 HDFS读取流程"></a>2.6.2 HDFS读取流程</h3><p>通过Client客户端中的DistributedFileSystem模块与NameNode进行交互，FSDataInputStream模块与DataNode进行交互</p>
<p><img src="/2023/03/08/Hadoop%E7%AC%94%E8%AE%B0/clip_image002-1678328490579.png" alt="img"></p>
<ul>
<li>client通过DistributedFileSystem向NameNode请求下载文件，NameNode通过查询元数据，找到block文件块所在的DataNode地址</li>
<li>按就近原则挑选一台DataNode服务器，请求读取数据</li>
<li>DataNode开始传输数据给客户断（从磁盘中读取数据输入流Stream，以Packet为单位来验证）</li>
<li>cilent客户端以Packet为单位接收，先再本地缓存，然后写入目标文件</li>
</ul>
<h1 id="3-MapReduce"><a href="#3-MapReduce" class="headerlink" title="3.MapReduce"></a>3.MapReduce</h1><h2 id="3-1-MapReduce定义"><a href="#3-1-MapReduce定义" class="headerlink" title="3.1 MapReduce定义"></a>3.1 MapReduce定义</h2><p>MapReduce是Hadoop的一套分布式运行程序框架。核心功能在于将用户编写的业务逻辑代码与自带默认组件整合，可以使用户在不了解分布式底层架构的情况下直接编写分布式运算程序</p>
<p><strong>1.MapReduce优点</strong></p>
<ul>
<li><p>易于编程</p>
<p>MapReduce通过简单的实现一些接口就可以完成分布式程序的编写</p>
</li>
<li><p>易扩展</p>
<p>基于分布式特点，计算资源得不到满足时可以轻松地通过增加集群机器的方式来扩展计算能力</p>
</li>
<li><p>高容错性</p>
<p>当集群中某一台机器挂掉时，MapReduce可以在没有人工参与的情况下把它上面的计算任务转移到另一个节点上运行</p>
</li>
<li><p>海量数据处理</p>
<p>上千台服务器并发工作，可达PB级以上</p>
</li>
</ul>
<p><strong>2.MapReduce缺点</strong></p>
<ul>
<li><p>不擅长实时计算</p>
<p>MapReduce适合海量数据的离线计算，但无法在秒级内进行处理，返回结果</p>
</li>
<li><p>不擅长流式计算</p>
<p>MapReduce因其自身设计特点决定数据源是静态的，不能有动态变化</p>
</li>
<li><p>不擅长DAG（有向无环图）计算</p>
<p>MapReduce自身设计中多个应用程序存在依赖关系，前一个应用程序的输出为后一个的输入。此种情况下每个MapReduce作业的输出结果都会写入磁盘，大量IO性能低下</p>
</li>
</ul>

    </div>

    
    
    

      <footer class="post-footer">

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2023/02/22/MySQL%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%8B%EF%BC%89/" rel="prev" title="MySQL笔记（下）">
      <i class="fa fa-chevron-left"></i> MySQL笔记（下）
    </a></div>
      <div class="post-nav-item"></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#1-Hadoop%E6%A6%82%E8%BF%B0"><span class="nav-text">1.Hadoop概述</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#2-HDFS"><span class="nav-text">2.HDFS</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#2-1-HDFS%E5%AE%9A%E4%B9%89"><span class="nav-text">2.1 HDFS定义</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-2-HDFS%E7%BB%84%E6%88%90%E6%9E%B6%E6%9E%84"><span class="nav-text">2.2 HDFS组成架构</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-3-HDFS%E6%96%87%E4%BB%B6%E5%9D%97%E5%A4%A7%E5%B0%8F"><span class="nav-text">2.3 HDFS文件块大小</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-4-HDFS%E5%9F%BA%E6%9C%AC%E5%91%BD%E4%BB%A4"><span class="nav-text">2.4 HDFS基本命令</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-5-HDFS-API"><span class="nav-text">2.5 HDFS API</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-6-HDFS%E8%AF%BB%E5%86%99%E6%B5%81%E7%A8%8B"><span class="nav-text">2.6 HDFS读写流程</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#2-6-1-HDFS%E5%86%99%E5%85%A5%E6%B5%81%E7%A8%8B"><span class="nav-text">2.6.1 HDFS写入流程</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-6-2-HDFS%E8%AF%BB%E5%8F%96%E6%B5%81%E7%A8%8B"><span class="nav-text">2.6.2 HDFS读取流程</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#3-MapReduce"><span class="nav-text">3.MapReduce</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#3-1-MapReduce%E5%AE%9A%E4%B9%89"><span class="nav-text">3.1 MapReduce定义</span></a></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="倬倬吃三碗"
      src="/images/zaomiao2.jpg">
  <p class="site-author-name" itemprop="name">倬倬吃三碗</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">23</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">7</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/zhuozhuo233" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;zhuozhuo233" rel="noopener" target="_blank"><i class="fa fa-fw fa-github"></i>GitHub</a>
      </span>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2023</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">倬倬吃三碗</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a> 强力驱动
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  

<script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"debug":false,"model":{"scale":1,"hHeadPos":0.5,"vHeadPos":0.618,"jsonPath":"/live2dw/assets/koharu.model.json"},"display":{"superSample":2,"width":300,"height":600,"position":"right","hOffset":0,"vOffset":-20},"mobile":{"show":false,"scale":0.2},"react":{"opacityDefault":0.7,"opacityOnHover":0.2},"log":false});</script></body>
</html>
